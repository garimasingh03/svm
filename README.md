# svm
The methodology involves optimizing a Nu-Support Vector Classifier (NuSVC) on the Iris dataset to find the best combination of kernel type and nu parameter for classification accuracy. The dataset is split into 10 different train-test samples, and for each split, the model is trained using various kernels (poly, sigmoid, linear, rbf) and randomly selected nu values within a safe range (based on class proportions). The accuracy is calculated for each configuration, and the best-performing kernel and nu are recorded per split. Finally, the globally best configuration is used to plot a learning curve, showing how model accuracy improves with increasing training data. This approach ensures robust evaluation by incorporating randomness, multiple data splits, and model tuning.
![image](https://github.com/user-attachments/assets/54c62685-2686-47f4-adfe-d2811692b718)
